---
description: Patron para pantallas de chat con input flotante y teclado en React Native
globs: 
alwaysApply: false
---

# Chat con Input Flotante y Teclado

## Dependencias

```bash
npx expo install react-native-keyboard-controller react-native-markdown-display
```

Añadir `KeyboardProvider` en el root layout.

## Layout: Teclado + Input Flotante

### Problema

Con un ScrollView normal + input flotante, cuando el teclado se abre el área de scroll NO se reduce. El contenido queda oculto detrás del teclado/input.

### Solución: KeyboardAwareScrollView + KeyboardStickyView

```typescript
import { KeyboardAwareScrollView, KeyboardStickyView } from 'react-native-keyboard-controller'

<YStack flex={1}>
  <KeyboardAwareScrollView
    style={{ flex: 1 }}
    contentContainerStyle={{ 
      paddingBottom: INPUT_BAR_HEIGHT + (isKeyboardOpen ? 0 : insets.bottom),
    }}
    keyboardShouldPersistTaps="handled"
    onScroll={handleScroll}
    scrollEventThrottle={16}
  >
    {/* Mensajes */}
  </KeyboardAwareScrollView>

  <KeyboardStickyView
    offset={{ closed: 0, opened: insets.bottom }}
    style={{ position: 'absolute', bottom: insets.bottom, left: 0, right: 0 }}
  >
    {/* Input */}
  </KeyboardStickyView>

  {/* Safe area bottom */}
  <YStack position="absolute" bottom={0} height={insets.bottom} backgroundColor="#000" />
</YStack>
```

### Clave: paddingBottom Dinámico

El `insets.bottom` solo debe sumarse cuando el teclado está CERRADO:

```typescript
const [isKeyboardOpen, setIsKeyboardOpen] = useState(false)

useEffect(() => {
  const showSub = Keyboard.addListener('keyboardDidShow', () => setIsKeyboardOpen(true))
  const hideSub = Keyboard.addListener('keyboardDidHide', () => setIsKeyboardOpen(false))
  return () => { showSub.remove(); hideSub.remove() }
}, [])

paddingBottom: INPUT_BAR_HEIGHT + (isKeyboardOpen ? 0 : insets.bottom)
```

### Evitar

- `KeyboardAvoidingView` de React Native - Problemático con Stack navigation
- `useKeyboardHandler` de keyboard-controller - Causa crashes
- `bottomOffset` en KeyboardAwareScrollView - Duplica espacio si ya tienes paddingBottom

## Streaming en Mobile

### Problema

El fetch nativo de React Native no soporta streaming correctamente. Los mensajes no aparecen hasta que la respuesta completa.

### Solución

Usar `fetch` de `expo/fetch`:

```typescript
import { fetch } from 'expo/fetch'

const response = await fetch(url, options)
const reader = response.body.getReader()

while (true) {
  const { value, done } = await reader.read()
  if (done) break
  const chunk = decoder.decode(value, { stream: true })
  onToken(chunk)
}
```

## Efecto Typewriter

### Problema

Los tokens de streaming llegan en chunks grandes y se ven bruscos.

### Solución: Buffer con Velocidad Dinámica

Acumular tokens en un buffer y mostrarlos gradualmente. La velocidad se adapta al tamaño del buffer para no quedarse atrás:

```typescript
const textBufferRef = useRef('')
const isTypingRef = useRef(false)

const typewriterLoop = () => {
  if (textBufferRef.current.length === 0) {
    isTypingRef.current = false
    return
  }
  
  const bufferSize = textBufferRef.current.length
  let charsToShow: number
  let delay: number
  
  // Velocidad dinamica segun buffer
  if (bufferSize < 10) {
    charsToShow = Math.floor(Math.random() * 2) + 1  // 1-2 chars
    delay = 20 + Math.random() * 15                   // 20-35ms
  } else if (bufferSize < 50) {
    charsToShow = Math.floor(Math.random() * 6) + 3  // 3-8 chars
    delay = 15 + Math.random() * 10                   // 15-25ms
  } else {
    charsToShow = Math.floor(Math.random() * 11) + 10 // 10-20 chars
    delay = 10                                         // 10ms (catch-up)
  }
  
  const chars = textBufferRef.current.slice(0, charsToShow)
  textBufferRef.current = textBufferRef.current.slice(charsToShow)
  
  // Actualizar mensaje...
  setTimeout(typewriterLoop, delay)
}

// En onToken:
onToken: (token) => {
  textBufferRef.current += token
  if (!isTypingRef.current) {
    isTypingRef.current = true
    typewriterLoop()
  }
}
```

## Markdown en Mensajes

### Dependencia

```bash
bun add react-native-markdown-display
```

### Uso

```typescript
import Markdown from 'react-native-markdown-display'

function AssistantMessage({ content, textColor, codeBackground }) {
  const markdownStyles = {
    body: { color: textColor, fontSize: 17, lineHeight: 24 },
    paragraph: { marginTop: 0, marginBottom: 16 },
    heading1: { color: textColor, fontSize: 24, fontWeight: '700', marginTop: 20, marginBottom: 12 },
    heading2: { color: textColor, fontSize: 20, fontWeight: '600', marginTop: 18, marginBottom: 10 },
    code_inline: { 
      backgroundColor: codeBackground, 
      paddingHorizontal: 4, 
      paddingVertical: 2,
      borderRadius: 4,
      fontFamily: Platform.OS === 'ios' ? 'Menlo' : 'monospace',
    },
    fence: { 
      backgroundColor: codeBackground, 
      padding: 12, 
      borderRadius: 8,
      marginVertical: 12,
      fontFamily: Platform.OS === 'ios' ? 'Menlo' : 'monospace',
    },
  }

  return <Markdown style={markdownStyles}>{content}</Markdown>
}
```

### Server: Instruir al Modelo

El modelo debe saber que puede usar markdown directamente:

```typescript
const SYSTEM_PROMPT = `...
Formatea tus respuestas usando Markdown de forma natural.
Escribe el markdown directamente, no lo envuelvas en bloques de codigo.
El cliente renderiza markdown de forma nativa.`
```

## Boton Flotante Scroll-to-Bottom

Mostrar un boton cuando el usuario ha scrolleado hacia arriba:

```typescript
const [showScrollButton, setShowScrollButton] = useState(false)

const handleScroll = (event) => {
  const { contentOffset, contentSize, layoutMeasurement } = event.nativeEvent
  const distanceFromBottom = contentSize.height - contentOffset.y - layoutMeasurement.height
  setShowScrollButton(distanceFromBottom > 50)
}

const handleScrollToBottom = () => {
  scrollRef.current?.scrollToEnd({ animated: true })
  setShowScrollButton(false)
}

// Renderizar boton flotante encima del input cuando showScrollButton es true
{showScrollButton && (
  <KeyboardStickyView
    offset={{ closed: 0, opened: insets.bottom }}
    style={{ position: 'absolute', bottom: insets.bottom + INPUT_BAR_HEIGHT + 8, right: 16 }}
  >
    <Pressable onPress={handleScrollToBottom}>
      <FontAwesome name="chevron-down" />
    </Pressable>
  </KeyboardStickyView>
)}
```

## Smart Auto-Scroll

El auto-scroll debe ser inteligente: activo por defecto, pero que el usuario pueda "escapar" scrolleando hacia arriba.

### Problema

El auto-scroll durante streaming "compite" con el scroll manual del usuario. Si el usuario intenta scrollear hacia arriba para leer contenido anterior, el auto-scroll lo devuelve al fondo.

### Solución: Detectar Scroll Manual del Usuario

Usar refs para trackear el estado del scroll y detectar cuando el usuario scrollea manualmente:

```typescript
const SCROLL_THRESHOLD = 50

// Smart auto-scroll refs
const lastScrollTime = useRef(0)
const lastScrollYRef = useRef(0)
const isAtBottomRef = useRef(true)
const userIsDraggingRef = useRef(false)

// Throttled scroll - solo si usuario está en el fondo
const scrollToBottom = useCallback(() => {
  if (!isAtBottomRef.current) return

  const now = Date.now()
  if (now - lastScrollTime.current < 100) return
  lastScrollTime.current = now

  setTimeout(() => {
    if (!isAtBottomRef.current) return // Double-check
    scrollRef.current?.scrollToEnd({ animated: false }) // Sin animación para no competir
  }, 50)
}, [])

// Detectar inicio de scroll manual
const handleScrollBeginDrag = useCallback((event) => {
  userIsDraggingRef.current = true
  // Cancelar cualquier scroll animado en progreso
  const currentY = event.nativeEvent.contentOffset.y
  scrollRef.current?.scrollTo({ y: currentY, animated: false })
}, [])

// Detectar dirección del scroll
const handleScroll = useCallback((event) => {
  const { contentOffset, contentSize, layoutMeasurement } = event.nativeEvent
  const distanceFromBottom = contentSize.height - contentOffset.y - layoutMeasurement.height
  const isAtBottom = distanceFromBottom <= SCROLL_THRESHOLD

  if (userIsDraggingRef.current) {
    const scrolledUp = contentOffset.y < lastScrollYRef.current - 5

    if (scrolledUp) {
      // Usuario scrolleó hacia arriba - desactivar auto-scroll
      isAtBottomRef.current = false
    } else if (isAtBottom) {
      // Usuario llegó al fondo - reactivar auto-scroll
      isAtBottomRef.current = true
    }
  }

  lastScrollYRef.current = contentOffset.y
  setShowScrollButton(!isAtBottom)
}, [])

// Finalizar estado cuando termina el drag
const handleScrollEndDrag = useCallback((event) => {
  const { contentOffset, contentSize, layoutMeasurement, velocity } = event.nativeEvent
  const hasNoMomentum = !velocity || Math.abs(velocity.y) < 0.1

  if (hasNoMomentum) {
    userIsDraggingRef.current = false
    const distanceFromBottom = contentSize.height - contentOffset.y - layoutMeasurement.height
    isAtBottomRef.current = distanceFromBottom <= SCROLL_THRESHOLD
  }
}, [])

// Finalizar estado después del momentum scroll
const handleMomentumScrollEnd = useCallback((event) => {
  userIsDraggingRef.current = false
  const { contentOffset, contentSize, layoutMeasurement } = event.nativeEvent
  const distanceFromBottom = contentSize.height - contentOffset.y - layoutMeasurement.height
  isAtBottomRef.current = distanceFromBottom <= SCROLL_THRESHOLD
}, [])
```

### Uso en ScrollView

```typescript
<KeyboardAwareScrollView
  onScroll={handleScroll}
  onScrollBeginDrag={handleScrollBeginDrag}
  onScrollEndDrag={handleScrollEndDrag}
  onMomentumScrollEnd={handleMomentumScrollEnd}
  scrollEventThrottle={16}
>
```

### Claves

- `userIsDraggingRef`: Solo actualizar `isAtBottomRef` cuando el usuario scrollea manualmente
- `animated: false` en `scrollToEnd`: El scroll instantáneo no compite con el usuario
- Cancelar scroll animado en `handleScrollBeginDrag`: Cuando el usuario empieza a scrollear, detener cualquier scroll automático
- Cuando el usuario envía un mensaje, siempre hacer `isAtBottomRef.current = true` para reactivar auto-scroll

## Input Siempre Editable

El usuario puede escribir mientras el agente responde, pero el botón de envío está deshabilitado:

```typescript
<Input
  value={input}
  onChangeText={setInput}
  // Sin editable={false} - siempre editable
/>
<Pressable
  onPress={handleSend}
  disabled={isSending || !input.trim()}
>
```

## Chat Fuera de Tabs

Si el chat debe superponerse a las tabs, la ruta debe estar a nivel raiz:

```
app/
  chat.tsx        # Nivel raiz, se superpone a tabs
  (tabs)/
    ...
```

## Mensajes de Audio

### Especificaciones

- Cuando el input está vacío, mostrar botón de micrófono en lugar de enviar
- Al grabar: mostrar waveform animado + botón X (cancelar) + botón enviar
- Al pulsar enviar: transcribir audio con Whisper y enviar automáticamente el texto
- Durante transcripción: mostrar "Transcribiendo..." con spinner en el botón
- El teclado debe permanecer abierto durante la grabación

### Dependencias

```bash
cd apps/zukus && bun add expo-audio
cd apps/server && bun add openai
```

Configurar `OPENAI_API_KEY` en el servidor (Fly.io secrets).

### Arquitectura

```
[Usuario pulsa mic] → [Grabando + Waveform] → [Pulsa enviar]
                                                    ↓
[UI muestra "Transcribiendo..."] ← [POST /transcribe]
                                                    ↓
[Whisper API] → [Texto] → [Se envía como mensaje normal]
```

### Hook de Grabación (expo-audio)

#### Workaround para Metering

expo-audio tiene bugs con metering. La solución es:
1. Pasar opciones con `isMeteringEnabled: true` a `useAudioRecorder()`
2. Llamar `prepareToRecordAsync()` SIN argumentos
3. Usar `useAudioRecorderState()` para polling del metering

Ver: https://github.com/expo/expo/issues/37241

```typescript
const recorderOptions = useMemo(
  () => ({
    ...RecordingPresets.HIGH_QUALITY,
    isMeteringEnabled: true,
  }),
  []
)

const recorder = useAudioRecorder(recorderOptions)
const recorderState = useAudioRecorderState(recorder, 100) // Poll cada 100ms

// Leer metering del estado
useEffect(() => {
  if (recorderState.isRecording && recorderState.metering !== undefined) {
    // Normalizar dB a 0-1 (valores típicos: -160 silencio, 0 máximo)
    const normalized = Math.max(0, Math.min(1, (recorderState.metering + 60) / 60))
    // Actualizar datos del waveform...
  }
}, [recorderState.isRecording, recorderState.metering])

// Al iniciar grabación: NO pasar opciones aquí
await recorder.prepareToRecordAsync()
recorder.record()
```

### Waveform Animado

Componente con barras que ocupan todo el ancho disponible:

```typescript
const DEFAULT_BAR_COUNT = 24
const BAR_WIDTH = 4
const MAX_BAR_HEIGHT = 28
const MIN_BAR_HEIGHT = 6

<View style={{ flex: 1, flexDirection: 'row', justifyContent: 'space-evenly', alignItems: 'center' }}>
  {animatedValues.map((height, index) => (
    <Animated.View
      key={index}
      style={{ width: BAR_WIDTH, height, backgroundColor: color, borderRadius: BAR_WIDTH / 2 }}
    />
  ))}
</View>
```

### Mantener Teclado Abierto Durante Grabación

#### Problema

Cuando el usuario pulsa grabar, si el Input se desmonta el teclado se cierra.

#### Solución

Mantener el Input SIEMPRE renderizado, solo ocultarlo visualmente cuando graba:

```typescript
{/* Waveform visible durante grabación */}
{(isRecording || isTranscribing) && (
  <XStack flex={1} alignItems="center" justifyContent="center">
    <AudioWaveform meteringData={meteringData} />
  </XStack>
)}

{/* Input siempre renderizado - oculto durante grabación */}
<Input
  flex={isRecording || isTranscribing ? 0 : 1}
  width={isRecording || isTranscribing ? 0 : undefined}
  opacity={isRecording || isTranscribing ? 0 : 1}
  pointerEvents={isRecording || isTranscribing ? 'none' : 'auto'}
  autoFocus
  // ... resto de props
/>
```

Clave: El Input nunca se desmonta, solo cambia su visibilidad. Esto mantiene el foco y el teclado abierto.

### Endpoint de Transcripción (Server)

```typescript
// apps/server/src/transcription.ts
import OpenAI, { toFile } from 'openai'

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

export async function handleTranscriptionRequest(request: Request) {
  // Validar auth...

  const formData = await request.formData()
  const audioFile = formData.get('audio') as File | null

  const arrayBuffer = await audioFile.arrayBuffer()
  const buffer = Buffer.from(arrayBuffer)

  const transcription = await openai.audio.transcriptions.create({
    file: await toFile(buffer, 'audio.m4a', { type: 'audio/m4a' }),
    model: 'whisper-1',
    language: 'es',
  })

  return Response.json({ text: transcription.text })
}
```

### Servicio Cliente

```typescript
// apps/zukus/services/transcription.ts
export async function transcribeAudio({ audioUri, accessToken }) {
  const formData = new FormData()

  // Web: blob URL
  if (audioUri.startsWith('blob:')) {
    const response = await fetch(audioUri)
    const blob = await response.blob()
    formData.append('audio', blob, 'recording.webm')
  } else {
    // Nativo: file:// URI
    formData.append('audio', {
      uri: audioUri,
      type: 'audio/m4a',
      name: 'recording.m4a',
    } as unknown as Blob)
  }

  const result = await fetch(`${serverBaseUrl}/transcribe`, {
    method: 'POST',
    headers: { Authorization: `Bearer ${accessToken}` },
    body: formData,
  })

  return result.json()
}
```

### Haptics (Solo Nativo)

Añadir feedback háptico para dar sensación nativa a las interacciones de audio:

```typescript
import * as Haptics from 'expo-haptics'

// Al empezar a grabar - feedback más notable
async function handleMicrophonePress() {
  Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Medium)
  await startRecording()
}

// Al enviar audio - feedback más sutil
async function handleSendAudio() {
  Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Light)
  // ... resto de la lógica
}
```

**Importante:** Solo aplicar haptics a acciones de audio, NO al envío de texto normal.

### Archivos Relacionados

| Archivo | Propósito |
|---------|-----------|
| `hooks/useAudioRecording.native.ts` | Hook grabación nativo con metering real |
| `hooks/useAudioRecording.web.ts` | Hook grabación web con metering simulado |
| `screens/chat/AudioWaveform.tsx` | Componente visual de barras animadas |
| `services/transcription.ts` | Cliente para endpoint de transcripción |
| `server/src/transcription.ts` | Handler del servidor con Whisper |
